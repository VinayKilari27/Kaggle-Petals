{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8iU2O9CWOJj8"
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "DBDMh6nyORKn",
    "outputId": "7edc388a-b2ca-47a1-e1ba-c3e4dbf8268f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4468/3338135192.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Upload kaggle API key file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload kaggle API key file\n",
    "files.upload()\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEaI8MrmOSWr",
    "outputId": "f7053968-8ddd-4681-84cd-699e05dbbb4b"
   },
   "outputs": [],
   "source": [
    "!kaggle competitions download -c tpu-getting-started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q32xXOL0OTmo",
    "outputId": "f00fc4d0-7816-49a6-f00b-33153ddedd24"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Unzip the dataset (the path might be different based on the dataset's structure)\n",
    "with zipfile.ZipFile('tpu-getting-started.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')\n",
    "\n",
    "# Check the dataset directory\n",
    "os.listdir('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZzybCk_TGUh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGyRy1snTDp2"
   },
   "outputs": [],
   "source": [
    "# Function to parse TFRecord files\n",
    "def _parse_function(proto):\n",
    "    # Define your `features` dictionary here and parse `proto`\n",
    "    features = {'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "                'image/class/label': tf.io.FixedLenFeature([], tf.int64)}\n",
    "    parsed_features = tf.io.parse_single_example(proto, features)\n",
    "    # Decode the JPEG image\n",
    "    image = tf.io.decode_jpeg(parsed_features['image/encoded'], channels=3)\n",
    "    image = tf.image.resize(image, [331, 331])  # Match the size of the images in the TFRecord\n",
    "    image = image / 255.0  # Normalize the pixel values\n",
    "    label = tf.cast(parsed_features['image/class/label'], tf.int32)\n",
    "    label = tf.one_hot(label, depth=104)  # Assuming there are 104 classes\n",
    "    return image, label\n",
    "\n",
    "# Function to load dataset\n",
    "def load_dataset(filepaths):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths)\n",
    "    dataset = dataset.map(_parse_function)  # Parse the record into tensors\n",
    "    dataset = dataset.shuffle(1024).batch(32)  # Shuffle and batch the dataset\n",
    "    return dataset\n",
    "\n",
    "# Assuming you want to use the 331x331 resolution\n",
    "train_files = tf.io.gfile.glob('data/tfrecords-jpeg-331x331/train/*.tfrec')\n",
    "val_files = tf.io.gfile.glob('data/tfrecords-jpeg-331x331/val/*.tfrec')  # Validation data\n",
    "\n",
    "train_dataset = load_dataset(train_files)\n",
    "val_dataset = load_dataset(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWsub7h-OWJN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(331, 331, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(104, activation='softmax')  # Update this to 104 to match the number of classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_dataset, epochs=5, validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91OB22r-OYxt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFzJYd8iP_eG"
   },
   "outputs": [],
   "source": [
    "# Experimenting with a deeper network\n",
    "deeper_model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "deeper_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrCVdBFpQAz0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Trying a different optimizer and learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVhZ1SNQQCnO"
   },
   "outputs": [],
   "source": [
    "# Experimenting with different data augmentation parameters\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXi0uXB8QEIA"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define a simple logger\n",
    "def log_experiment(experiment_name, history):\n",
    "    # Save the metrics from the `history` object into a file\n",
    "    with open(f'{experiment_name}_log.json', 'w') as f:\n",
    "        json.dump(history.history, f)\n",
    "\n",
    "# After training an experiment\n",
    "history = deeper_model.fit(train_generator, epochs=5)\n",
    "log_experiment('deeper_model', history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqwN4uhcQFTS"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime\n",
    "\n",
    "# Start a new experiment log\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with the callback\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "# You can then view the TensorBoard logs within Colab:\n",
    "%tensorboard --logdir logs/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_C0JgIvQGdT"
   },
   "outputs": [],
   "source": [
    "# Assuming you have logged several experiments in JSON files\n",
    "import os\n",
    "\n",
    "# Plot all the experiments\n",
    "plt.figure(figsize=(10, 6))\n",
    "for experiment_log in os.listdir('logs'):\n",
    "    if experiment_log.endswith('_log.json'):\n",
    "        with open(f'logs/{experiment_log}', 'r') as f:\n",
    "            history = json.load(f)\n",
    "            plt.plot(history['accuracy'], label=experiment_log.replace('_log.json', ''))\n",
    "\n",
    "plt.title('Comparison of experiment accuracies')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHVeH2CCRYu9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
